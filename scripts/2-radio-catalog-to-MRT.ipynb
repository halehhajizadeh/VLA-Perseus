{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da64f914-e5ee-4a14-99fc-fafb34d397a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Detected columns after remapping SPWs: ['Source_ID', 'RA', 'DEC', 'E_RA', 'E_DEC', 'Total_S_SPW1', 'E_Total_S_SPW1', 'Peak_S_SPW1', 'E_Peak_S_SPW1', 'RMS_SPW1', 'Total_S_SPW2', 'E_Total_S_SPW2', 'Peak_S_SPW2', 'E_Peak_S_SPW2', 'RMS_SPW2', 'Total_S_SPW3', 'E_Total_S_SPW3', 'Peak_S_SPW3', 'E_Peak_S_SPW3', 'RMS_SPW3', 'Total_S_SPW4', 'E_Total_S_SPW4', 'Peak_S_SPW4', 'E_Peak_S_SPW4', 'RMS_SPW4', 'Total_S_SPW5', 'E_Total_S_SPW5', 'Peak_S_SPW5', 'E_Peak_S_SPW5', 'RMS_SPW5', 'Total_S_SPW6', 'E_Total_S_SPW6', 'Peak_S_SPW6', 'E_Peak_S_SPW6', 'RMS_SPW6', 'Total_S_SPW7', 'E_Total_S_SPW7', 'Peak_S_SPW7', 'E_Peak_S_SPW7', 'RMS_SPW7', 'Total_S_SPW8', 'E_Total_S_SPW8', 'Peak_S_SPW8', 'E_Peak_S_SPW8', 'RMS_SPW8', 'Total_S_SPW9', 'E_Total_S_SPW9', 'Peak_S_SPW9', 'E_Peak_S_SPW9', 'RMS_SPW9', 'alpha', 'E_alpha']\n",
      "âœ… Saved MRT file with full header to: ../paper1/csv/combined_sources_with_alpha_mrt.txt\n",
      "âœ… Saved data-only file (formatted & no header) to: ../paper1/csv/combined_sources_with_alpha_data_only.txt\n",
      "\n",
      "ðŸ‘‰ Copy and paste this format code into the AAS 'format code' box:\n",
      "\n",
      "A20 F10.5 F10.5 F10.5 F10.5 F6.2 F6.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2 F8.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "# === Input/Output Files ===\n",
    "input_csv        = \"../paper1/csv/combined_sources_with_alpha.csv\"\n",
    "output_mrt       = \"../paper1/csv/combined_sources_with_alpha_mrt.txt\"\n",
    "output_data_only = \"../paper1/csv/combined_sources_with_alpha_data_only.txt\"\n",
    "\n",
    "# === Load Data ===\n",
    "df = pd.read_csv(input_csv)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# (Optional) If you ever want to regenerate Source_ID from RA/DEC, uncomment this:\n",
    "# def truncate_sexagesimal(ra_deg, dec_deg):\n",
    "#     coord = SkyCoord(ra=ra_deg*u.deg, dec=dec_deg*u.deg)\n",
    "#     ra_str = coord.ra.to_string(unit=u.hourangle, sep='', precision=1, pad=True)\n",
    "#     dec_str = coord.dec.to_string(unit=u.deg, sep='', alwayssign=True, precision=1, pad=True)\n",
    "#     ra_trunc = ra_str.split('.')[0] + '.' + ra_str.split('.')[1][0]\n",
    "#     dec_trunc = dec_str.split('.')[0] + '.' + dec_str.split('.')[1][0]\n",
    "#     return f\"VPR J{ra_trunc}{dec_trunc}\"\n",
    "# df['Source_ID'] = df.apply(lambda row: truncate_sexagesimal(row['RA'], row['DEC']), axis=1)\n",
    "\n",
    "# === Standardize Column Names ===\n",
    "rename_dict = {}\n",
    "for col in df.columns:\n",
    "    if \"_spw\" in col:\n",
    "        new_col = col.replace(\"_spw\", \"_SPW\")\n",
    "        rename_dict[col] = new_col\n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "# === Map SPWs from original to 1â€“9 ===\n",
    "spw_map = {\n",
    "    15: 1,\n",
    "    16: 2,\n",
    "    17: 3,\n",
    "    2:  4,\n",
    "    3:  5,\n",
    "    4:  6,\n",
    "    5:  7,\n",
    "    6:  8,\n",
    "    8:  9\n",
    "}\n",
    "remap_dict = {}\n",
    "for col in df.columns:\n",
    "    match = re.search(r'_SPW(\\d+)', col)\n",
    "    if match:\n",
    "        old_spw = int(match.group(1))\n",
    "        if old_spw in spw_map:\n",
    "            new_spw = spw_map[old_spw]\n",
    "            new_col = re.sub(r'_SPW\\d+', f'_SPW{new_spw}', col)\n",
    "            remap_dict[col] = new_col\n",
    "\n",
    "df = df.rename(columns=remap_dict)\n",
    "print(\"âœ… Detected columns after remapping SPWs:\", df.columns.tolist())\n",
    "\n",
    "# === Define Column Groups ===\n",
    "ra_dec_cols  = ['RA', 'DEC', 'E_RA', 'E_DEC']\n",
    "alpha_cols   = ['alpha', 'E_alpha']\n",
    "isl_rms_cols = [col for col in df.columns if col.startswith(\"RMS_SPW\")]\n",
    "flux_cols    = [col for col in df.columns\n",
    "                if col.startswith(\"Total_S_SPW\")\n",
    "                or col.startswith(\"E_Total_S_SPW\")\n",
    "                or col.startswith(\"Peak_S_SPW\")\n",
    "                or col.startswith(\"E_Peak_S_SPW\")]\n",
    "\n",
    "columns = ['Source_ID'] + ra_dec_cols + alpha_cols + flux_cols + isl_rms_cols\n",
    "\n",
    "# === Convert RMS from mJy to ÂµJy ===\n",
    "# (Everything in RMS_SPW* is currently in mJy; convert to ÂµJy)\n",
    "for c in isl_rms_cols:\n",
    "    df[c] = df[c] * 1000.0\n",
    "\n",
    "# === Create Header Rows ===\n",
    "labels = columns\n",
    "\n",
    "# Units\n",
    "units = []\n",
    "for col in columns:\n",
    "    if col in ['RA', 'DEC', 'E_RA', 'E_DEC']:\n",
    "        units.append('deg')\n",
    "    elif col in ['alpha', 'E_alpha']:\n",
    "        units.append('---')\n",
    "    elif (col.startswith('Total_S_SPW') or\n",
    "          col.startswith('E_Total_S_SPW') or\n",
    "          col.startswith('Peak_S_SPW') or\n",
    "          col.startswith('E_Peak_S_SPW')):\n",
    "        # Fluxes remain in mJy, 2 decimal places\n",
    "        units.append('mJy')\n",
    "    elif col.startswith('RMS_SPW'):\n",
    "        # RMS now in ÂµJy, 2 decimal places\n",
    "        units.append('uJy')\n",
    "    elif col == 'Source_ID':\n",
    "        units.append('---')\n",
    "    else:\n",
    "        units.append('---')\n",
    "\n",
    "# Explanations\n",
    "explanations = []\n",
    "for col in columns:\n",
    "    if col == 'Source_ID':\n",
    "        explanations.append('IAU-compliant source name')\n",
    "    elif col == 'RA':\n",
    "        explanations.append('Right ascension (J2000) in degrees')\n",
    "    elif col == 'DEC':\n",
    "        explanations.append('Declination (J2000) in degrees')\n",
    "    elif col == 'E_RA':\n",
    "        explanations.append('Error in RA [deg]')\n",
    "    elif col == 'E_DEC':\n",
    "        explanations.append('Error in DEC [deg]')\n",
    "    elif col == 'alpha':\n",
    "        explanations.append('Spectral index')\n",
    "    elif col == 'E_alpha':\n",
    "        explanations.append('Error in spectral index')\n",
    "    elif 'Total_S_SPW' in col:\n",
    "        explanations.append('Integrated flux density in this SPW')\n",
    "    elif 'E_Total_S_SPW' in col:\n",
    "        explanations.append('Error on integrated flux density in this SPW')\n",
    "    elif 'Peak_S_SPW' in col:\n",
    "        explanations.append('Peak flux density in this SPW')\n",
    "    elif 'E_Peak_S_SPW' in col:\n",
    "        explanations.append('Error on peak flux density in this SPW')\n",
    "    elif 'RMS_SPW' in col:\n",
    "        explanations.append('Island RMS noise in this SPW')\n",
    "    else:\n",
    "        explanations.append('')\n",
    "\n",
    "# === APJ format codes (for the AAS \"format code\" box) ===\n",
    "formats = []\n",
    "for col in columns:\n",
    "    if col == 'Source_ID':\n",
    "        formats.append('A20')        # string\n",
    "    elif col in ['RA', 'DEC', 'E_RA', 'E_DEC']:\n",
    "        formats.append('F10.5')      # 5 decimal places in deg\n",
    "    elif col in ['alpha', 'E_alpha']:\n",
    "        formats.append('F6.2')       # 2 decimal places\n",
    "    else:\n",
    "        formats.append('F8.2')       # fluxes and RMS: 2 decimal places\n",
    "\n",
    "# === Separate Python format codes for actual text formatting ===\n",
    "py_formats = []\n",
    "for col in columns:\n",
    "    if col == 'Source_ID':\n",
    "        py_formats.append('s20')     # string, width 20\n",
    "    elif col in ['RA', 'DEC', 'E_RA', 'E_DEC']:\n",
    "        py_formats.append('f10.5')   # 5 decimal places\n",
    "    elif col in ['alpha', 'E_alpha']:\n",
    "        py_formats.append('f6.2')    # 2 decimal places\n",
    "    else:\n",
    "        py_formats.append('f8.2')    # 2 decimal places\n",
    "\n",
    "\n",
    "# === Helper Function for Formatting ===\n",
    "def format_fixed(x, fmt):\n",
    "    \"\"\"\n",
    "    fmt: 's20', 'i5', 'f8.2', etc. (Python-style helper, NOT the APJ code)\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        # For floats/ints, return correct-width blanks so columns stay aligned\n",
    "        spec = fmt[0]\n",
    "        if spec in ['f', 'i']:\n",
    "            width = int(fmt[1:].split('.')[0]) if '.' in fmt[1:] else int(fmt[1:])\n",
    "            return ''.rjust(width)\n",
    "        return ''\n",
    "    spec = fmt[0]\n",
    "    if spec == 's':\n",
    "        width = int(fmt[1:])\n",
    "        return f\"{str(x):>{width}s}\"\n",
    "    elif spec == 'i':\n",
    "        width = int(fmt[1:])\n",
    "        return f\"{int(x):>{width}d}\"\n",
    "    elif spec == 'f':\n",
    "        # f[width].[precision]\n",
    "        width_precision = fmt[1:].split('.')\n",
    "        width = int(width_precision[0])\n",
    "        precision = int(width_precision[1])\n",
    "        return f\"{float(x):>{width}.{precision}f}\"\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "# === Format Data Rows ===\n",
    "formatted_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    formatted_row = []\n",
    "    for col, pyfmt in zip(columns, py_formats):\n",
    "        formatted_row.append(format_fixed(row[col], pyfmt))\n",
    "    formatted_rows.append(' '.join(formatted_row))\n",
    "\n",
    "# === Save MRT File with Header ===\n",
    "with open(output_mrt, 'w') as f:\n",
    "    f.write(' '.join(labels) + '\\n')\n",
    "    f.write(' '.join(units) + '\\n')\n",
    "    f.write(' '.join(explanations) + '\\n')\n",
    "    f.write(' '.join(formats) + '\\n')  # AAS-style format codes\n",
    "    for line in formatted_rows:\n",
    "        f.write(line + '\\n')\n",
    "print(f\"âœ… Saved MRT file with full header to: {output_mrt}\")\n",
    "\n",
    "# === Save Data-Only File ===\n",
    "with open(output_data_only, 'w') as f:\n",
    "    for line in formatted_rows:\n",
    "        f.write(line + '\\n')\n",
    "print(f\"âœ… Saved data-only file (formatted & no header) to: {output_data_only}\")\n",
    "\n",
    "# === PRINT the format code string ===\n",
    "print(\"\\nðŸ‘‰ Copy and paste this format code into the AAS 'format code' box:\\n\")\n",
    "print(' '.join(formats))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831560ee-bf50-4549-b256-38c9864969fb",
   "metadata": {},
   "source": [
    "# Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a2c268-5fd5-4e71-a38a-68b55430ede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table*}[ht!]\n",
      "\\scriptsize\n",
      "\\setlength{\\tabcolsep}{2pt}\n",
      "\\renewcommand{\\arraystretch}{1.1}\n",
      "\\centering\n",
      "\\caption{Example rows from the catalog showing RA, Dec, flux densities, and associated uncertainties for sources in SPW1. The full catalog includes all 9 SPWs and is available online in machine-readable format.}\n",
      "\\label{tab:spw15-matched}\n",
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "Source\\_ID & RA & E\\_RA & DEC & E\\_DEC & Total\\_S\\_SPW1 & E\\_Total\\_S\\_SPW1 & Peak\\_S\\_SPW1 & E\\_Peak\\_S\\_SPW1 & RMS\\_SPW1 \\\\\n",
      "--- & deg & deg & deg & deg & mJy & mJy & mJy & mJy & $\\mu$Jy \\\\\n",
      "\\midrule\n",
      "VPR J033003.7+303256.0 & 52.51526 & 0.00158 & 30.54888 & 0.00195 & 149.17 & 28.71 & 54.13 & 7.93 & 7.42 \\\\\n",
      "VPR J033003.0+303533.6 & 52.51231 & 0.00100 & 30.59268 & 0.00167 & 40.98 & 12.38 & 39.33 & 6.87 & 6.90 \\\\\n",
      "VPR J032959.1+303622.3 & 52.49627 & 0.00327 & 30.60620 & 0.00122 & 19.32 & 10.67 & 21.85 & 6.39 & 6.90 \\\\\n",
      "VPR J032942.6+320502.7 & 52.42739 & 0.00036 & 32.08407 & 0.00032 & 223.45 & 15.69 & 183.92 & 7.94 & 7.62 \\\\\n",
      "VPR J032940.2+312455.1 & 52.41754 & 0.00023 & 31.41532 & 0.00021 & 316.33 & 28.67 & 270.64 & 14.90 & 14.39 \\\\\n",
      "VPR J032916.1+320651.4 & 52.31725 & 0.00110 & 32.11426 & 0.00100 & 66.76 & 14.49 & 55.91 & 7.41 & 7.15 \\\\\n",
      "VPR J032911.6+323609.2 & 52.29841 & 0.00023 & 32.60256 & 0.00042 & 330.91 & 30.07 & 319.32 & 16.92 & 16.81 \\\\\n",
      "VPR J032843.1+313912.5 & 52.17958 & 0.00005 & 31.65348 & 0.00005 & 99.13 & 1.15 & 96.60 & 0.66 & 0.65 \\\\\n",
      "VPR J032840.4+304954.5 & 52.16814 & 0.00002 & 30.83181 & 0.00002 & 197.62 & 8.99 & 177.28 & 4.82 & 4.71 \\\\\n",
      "VPR J032831.6+305045.1 & 52.13153 & 0.00088 & 30.84587 & 0.00051 & 70.95 & 12.82 & 52.99 & 5.95 & 5.80 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table*}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "# === File paths ===\n",
    "spw15_path = '../paper1/csv/spw15.csv'\n",
    "combined_sources_path = '../paper1/csv/combined_sources_with_alpha.csv'  # or _with_existing_alpha.csv if you prefer\n",
    "\n",
    "# === Load CSV files ===\n",
    "df_spw15 = pd.read_csv(spw15_path)\n",
    "df_combined = pd.read_csv(combined_sources_path)\n",
    "\n",
    "# === SkyCoord for RA/DEC matching ===\n",
    "coords_spw15 = SkyCoord(ra=df_spw15['RA'].values * u.deg,\n",
    "                        dec=df_spw15['DEC'].values * u.deg)\n",
    "coords_combined = SkyCoord(ra=df_combined['RA'].values * u.deg,\n",
    "                           dec=df_combined['DEC'].values * u.deg)\n",
    "\n",
    "# === Nearest neighbor match within 40 arcsec ===\n",
    "idx, d2d, _ = coords_spw15.match_to_catalog_sky(coords_combined)\n",
    "tolerance = 40 * u.arcsec\n",
    "matched_mask = d2d < tolerance\n",
    "\n",
    "# === Matched DataFrame ===\n",
    "df_matched = df_spw15[matched_mask].copy()\n",
    "\n",
    "# Attach Source_ID and (optionally) RA/DEC, E_RA, E_DEC from combined catalog\n",
    "df_matched['Source_ID'] = df_combined.iloc[idx[matched_mask]]['Source_ID'].values\n",
    "df_matched['RA']        = df_combined.iloc[idx[matched_mask]]['RA'].values\n",
    "df_matched['DEC']       = df_combined.iloc[idx[matched_mask]]['DEC'].values\n",
    "\n",
    "if 'E_RA' in df_combined.columns and 'E_DEC' in df_combined.columns:\n",
    "    df_matched['E_RA']  = df_combined.iloc[idx[matched_mask]]['E_RA'].values\n",
    "    df_matched['E_DEC'] = df_combined.iloc[idx[matched_mask]]['E_DEC'].values\n",
    "\n",
    "# === Convert RMS from mJy to ÂµJy ===\n",
    "# Isl_rms in spw15 is in mJy; convert to ÂµJy for the table\n",
    "if 'Isl_rms' in df_matched.columns:\n",
    "    df_matched['Isl_rms'] = df_matched['Isl_rms'] * 1000.0\n",
    "\n",
    "# === Define columns & LaTeX header (SPW15 â†’ SPW1 in naming) ===\n",
    "column_order = [\n",
    "    'Source_ID',\n",
    "    'RA', 'E_RA',\n",
    "    'DEC', 'E_DEC',\n",
    "    'Total_flux', 'E_Total_flux',\n",
    "    'Peak_flux', 'E_Peak_flux',\n",
    "    'Isl_rms'\n",
    "]\n",
    "\n",
    "# We will *display* them with these LaTeX labels:\n",
    "latex_header = [\n",
    "    'Source\\\\_ID',\n",
    "    'RA', 'E\\\\_RA',\n",
    "    'DEC', 'E\\\\_DEC',\n",
    "    'Total\\\\_S\\\\_SPW1', 'E\\\\_Total\\\\_S\\\\_SPW1',\n",
    "    'Peak\\\\_S\\\\_SPW1', 'E\\\\_Peak\\\\_S\\\\_SPW1',\n",
    "    'RMS\\\\_SPW1'\n",
    "]\n",
    "\n",
    "latex_units = [\n",
    "    '---',\n",
    "    'deg', 'deg',\n",
    "    'deg', 'deg',\n",
    "    'mJy', 'mJy',\n",
    "    'mJy', 'mJy',\n",
    "    '$\\\\mu$Jy'\n",
    "]\n",
    "\n",
    "# === Keep available columns only and take first 10 ===\n",
    "available_cols = [c for c in column_order if c in df_matched.columns]\n",
    "df_final = df_matched[available_cols].head(10).copy()\n",
    "\n",
    "# Make sure header & units are consistent with available columns\n",
    "col_to_label = dict(zip(column_order, latex_header))\n",
    "col_to_unit  = dict(zip(column_order, latex_units))\n",
    "\n",
    "labels = [col_to_label[c] for c in available_cols]\n",
    "units  = [col_to_unit[c]  for c in available_cols]\n",
    "\n",
    "# === Generate LaTeX table in the requested style ===\n",
    "colspec = 'l' * len(available_cols)  # e.g., llllllllll\n",
    "\n",
    "latex_table = r\"\"\"\\begin{table*}[ht!]\n",
    "\\scriptsize\n",
    "\\setlength{\\tabcolsep}{2pt}\n",
    "\\renewcommand{\\arraystretch}{1.1}\n",
    "\\centering\n",
    "\\caption{Example rows from the catalog showing RA, Dec, flux densities, and associated uncertainties for sources in SPW1. The full catalog includes all 9 SPWs and is available online in machine-readable format.}\n",
    "\\label{tab:spw15-matched}\n",
    "\\begin{tabular}{%s}\n",
    "\\toprule\n",
    "%s \\\\\n",
    "%s \\\\\n",
    "\\midrule\n",
    "\"\"\" % (\n",
    "    colspec,\n",
    "    ' & '.join(labels),\n",
    "    ' & '.join(units)\n",
    ")\n",
    "\n",
    "# === Add table rows ===\n",
    "for _, row in df_final.iterrows():\n",
    "    row_entries = []\n",
    "    for col in available_cols:\n",
    "        val = row[col]\n",
    "        if isinstance(val, (float, int)) and not pd.isna(val):\n",
    "            # RA/DEC and their errors: 5 decimals\n",
    "            if col in ['RA', 'DEC', 'E_RA', 'E_DEC']:\n",
    "                row_entries.append(f\"{val:.5f}\")\n",
    "            else:\n",
    "                # fluxes and RMS: 2 decimals\n",
    "                row_entries.append(f\"{val:.2f}\")\n",
    "        else:\n",
    "            row_entries.append(str(val))\n",
    "    latex_table += ' & '.join(row_entries) + r\" \\\\\" + \"\\n\"\n",
    "\n",
    "latex_table += r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cab6e5-5a8b-4635-a680-03d0ed1703ed",
   "metadata": {},
   "source": [
    "# Finding tolerance suitable for matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d60556-939f-42d1-9d17-bf6b3ac86974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Positional Uncertainty Statistics ===\n",
      "\n",
      "Units: degrees\n",
      "E_RA  : mean = 1.055641e-03, median = 9.264230e-04, max = 5.228767e-03\n",
      "E_DEC : mean = 1.011823e-03, median = 9.439699e-04, max = 5.464583e-03\n",
      "\n",
      "Units: arcseconds\n",
      "E_RA  : mean = 3.800, median = 3.335, max = 18.824 arcsec\n",
      "E_DEC : mean = 3.643, median = 3.398, max = 19.672 arcsec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ======================================\n",
    "# Input file\n",
    "# ======================================\n",
    "input_csv = \"../paper1/csv/combined_sources_with_alpha.csv\"\n",
    "\n",
    "# ======================================\n",
    "# Load data\n",
    "# ======================================\n",
    "df = pd.read_csv(input_csv)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# ======================================\n",
    "# Ensure numeric values\n",
    "# ======================================\n",
    "for col in [\"E_RA\", \"E_DEC\"]:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# ======================================\n",
    "# Conversion factor\n",
    "# ======================================\n",
    "DEG_TO_ARCSEC = 3600.0\n",
    "\n",
    "# ======================================\n",
    "# Statistics (degrees)\n",
    "# ======================================\n",
    "era_mean_deg    = df[\"E_RA\"].mean()\n",
    "era_median_deg  = df[\"E_RA\"].median()\n",
    "era_max_deg     = df[\"E_RA\"].max()\n",
    "\n",
    "edec_mean_deg   = df[\"E_DEC\"].mean()\n",
    "edec_median_deg = df[\"E_DEC\"].median()\n",
    "edec_max_deg    = df[\"E_DEC\"].max()\n",
    "\n",
    "# ======================================\n",
    "# Statistics (arcseconds)\n",
    "# ======================================\n",
    "era_mean_arcsec    = era_mean_deg    * DEG_TO_ARCSEC\n",
    "era_median_arcsec  = era_median_deg  * DEG_TO_ARCSEC\n",
    "era_max_arcsec     = era_max_deg     * DEG_TO_ARCSEC\n",
    "\n",
    "edec_mean_arcsec   = edec_mean_deg   * DEG_TO_ARCSEC\n",
    "edec_median_arcsec = edec_median_deg * DEG_TO_ARCSEC\n",
    "edec_max_arcsec    = edec_max_deg    * DEG_TO_ARCSEC\n",
    "\n",
    "# ======================================\n",
    "# Print results\n",
    "# ======================================\n",
    "print(\"=== Positional Uncertainty Statistics ===\")\n",
    "\n",
    "print(\"\\nUnits: degrees\")\n",
    "print(f\"E_RA  : mean = {era_mean_deg:.6e}, median = {era_median_deg:.6e}, max = {era_max_deg:.6e}\")\n",
    "print(f\"E_DEC : mean = {edec_mean_deg:.6e}, median = {edec_median_deg:.6e}, max = {edec_max_deg:.6e}\")\n",
    "\n",
    "print(\"\\nUnits: arcseconds\")\n",
    "print(f\"E_RA  : mean = {era_mean_arcsec:.3f}, median = {era_median_arcsec:.3f}, max = {era_max_arcsec:.3f} arcsec\")\n",
    "print(f\"E_DEC : mean = {edec_mean_arcsec:.3f}, median = {edec_median_arcsec:.3f}, max = {edec_max_arcsec:.3f} arcsec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032edf72-ce17-4e56-943b-58c3297dee24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe498b2-d899-4c3c-b15c-503ed1a432b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0021a7-08cc-4d60-b8b0-871ca631d6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
